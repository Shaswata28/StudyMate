# Backend Flow - How User Prompts Reach the AI

## ğŸ¯ Complete Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER SENDS MESSAGE                          â”‚
â”‚                    "Explain photosynthesis"                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: FastAPI Backend (python-backend/routers/chat.py)          â”‚
â”‚  POST /api/courses/{course_id}/chat                                â”‚
â”‚                                                                     â”‚
â”‚  â€¢ Verify user authentication                                      â”‚
â”‚  â€¢ Verify course ownership                                         â”‚
â”‚  â€¢ Get user context (academic info, preferences)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: Intent Classification (NEW!)                              â”‚
â”‚  Service: intent_classifier.py                                     â”‚
â”‚                                                                     â”‚
â”‚  Sends to: http://localhost:8001/classify                          â”‚
â”‚  Payload:                                                           â”‚
â”‚    {                                                                â”‚
â”‚      "query": "Explain photosynthesis",                            â”‚
â”‚      "subject": "Biology",                                          â”‚
â”‚      "grade": "Bachelor"                                            â”‚
â”‚    }                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: Router Model (ai-brain/brain.py)                          â”‚
â”‚  Endpoint: POST /classify                                           â”‚
â”‚  Model: Gemma 3 270M (studymate-router)                            â”‚
â”‚                                                                     â”‚
â”‚  Input Format (ChatML):                                             â”‚
â”‚    [                                                                â”‚
â”‚      {                                                              â”‚
â”‚        "role": "system",                                            â”‚
â”‚        "content": "You are a router. Classify..."                  â”‚
â”‚      },                                                             â”‚
â”‚      {                                                              â”‚
â”‚        "role": "user",                                              â”‚
â”‚        "content": "Context: Subject=Biology, grade=Bachelor.\n     â”‚
â”‚                    Query: Explain photosynthesis"                  â”‚
â”‚      }                                                              â”‚
â”‚    ]                                                                â”‚
â”‚                                                                     â”‚
â”‚  Router Model Output:                                               â”‚
â”‚    {                                                                â”‚
â”‚      "intent": "academic",                                          â”‚
â”‚      "needs_rag": true,                                             â”‚
â”‚      "needs_history": false,                                        â”‚
â”‚      "confidence": 0.85                                             â”‚
â”‚    }                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: Decision Point (chat.py)                                  â”‚
â”‚                                                                     â”‚
â”‚  IF intent == "safety":                                             â”‚
â”‚    â†’ Block immediately, return safety message                       â”‚
â”‚                                                                     â”‚
â”‚  IF needs_rag == true:                                              â”‚
â”‚    â†’ Proceed to RAG search                                          â”‚
â”‚  ELSE:                                                              â”‚
â”‚    â†’ Skip RAG search (SAVES TIME!)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: Conditional RAG Search (if needs_rag == true)             â”‚
â”‚  Service: service_manager.processing_service                        â”‚
â”‚                                                                     â”‚
â”‚  â€¢ Search course materials using semantic search                   â”‚
â”‚  â€¢ Query: "Explain photosynthesis"                                 â”‚
â”‚  â€¢ Limit: 3 most relevant materials                                â”‚
â”‚                                                                     â”‚
â”‚  Results:                                                           â”‚
â”‚    [                                                                â”‚
â”‚      {                                                              â”‚
â”‚        "name": "Biology Notes - Chapter 5",                         â”‚
â”‚        "excerpt": "Photosynthesis is the process...",              â”‚
â”‚        "similarity_score": 0.89                                     â”‚
â”‚      },                                                             â”‚
â”‚      ...                                                            â”‚
â”‚    ]                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 6: Build Adaptive Context (NEW!)                             â”‚
â”‚  Service: context_service.build_adaptive_context()                 â”‚
â”‚                                                                     â”‚
â”‚  Builds ChatML messages based on intent:                            â”‚
â”‚                                                                     â”‚
â”‚  Message 1 (System):                                                â”‚
â”‚    {                                                                â”‚
â”‚      "role": "system",                                              â”‚
â”‚      "content": "You are StudyMate, an AI tutor.\n\n               â”‚
â”‚                  [STUDENT PROFILE]\n                                â”‚
â”‚                  Academic Level: Bachelor\n                         â”‚
â”‚                  Subject: Biology\n\n                               â”‚
â”‚                  [LEARNING PREFERENCES]\n                           â”‚
â”‚                  Detail Level: 0.7/1.0\n                            â”‚
â”‚                  Learning Pace: moderate\n\n                        â”‚
â”‚                  [COURSE MATERIALS]\n                               â”‚
â”‚                  1. Biology Notes - Chapter 5 (relevance: 0.89)\n  â”‚
â”‚                     Photosynthesis is the process..."               â”‚
â”‚    }                                                                â”‚
â”‚                                                                     â”‚
â”‚  Message 2 (User):                                                  â”‚
â”‚    {                                                                â”‚
â”‚      "role": "user",                                                â”‚
â”‚      "content": "Explain photosynthesis"                           â”‚
â”‚    }                                                                â”‚
â”‚                                                                     â”‚
â”‚  (If needs_history == true, adds previous messages here)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 7: Send to Core Model                                        â”‚
â”‚  Service: local_ai_service.generate_chat_response()                â”‚
â”‚                                                                     â”‚
â”‚  HTTP POST to: http://localhost:8001/chat                          â”‚
â”‚  Payload:                                                           â”‚
â”‚    {                                                                â”‚
â”‚      "messages": [                                                  â”‚
â”‚        {"role": "system", "content": "..."},                        â”‚
â”‚        {"role": "user", "content": "Explain photosynthesis"}       â”‚
â”‚      ],                                                             â”‚
â”‚      "model": "studymate"                                           â”‚
â”‚    }                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 8: Core Model Generation (ai-brain/brain.py)                 â”‚
â”‚  Endpoint: POST /chat                                               â”‚
â”‚  Model: StudyMate (Qwen-based)                                     â”‚
â”‚                                                                     â”‚
â”‚  Uses: ollama.chat() API                                            â”‚
â”‚                                                                     â”‚
â”‚  await client.chat(                                                 â”‚
â”‚      model="studymate",                                             â”‚
â”‚      messages=[...],  # ChatML format                               â”‚
â”‚      options={                                                      â”‚
â”‚          "temperature": 0.45,                                       â”‚
â”‚          "top_p": 0.9,                                              â”‚
â”‚          "repeat_penalty": 1.15,                                    â”‚
â”‚          "num_ctx": 4096,                                           â”‚
â”‚          "num_predict": 1024                                        â”‚
â”‚      }                                                              â”‚
â”‚  )                                                                  â”‚
â”‚                                                                     â”‚
â”‚  Core Model Output:                                                 â”‚
â”‚    "Photosynthesis is the process by which plants convert          â”‚
â”‚     light energy into chemical energy. Based on your notes,        â”‚
â”‚     it occurs in chloroplasts and involves two main stages:        â”‚
â”‚     the light-dependent reactions and the Calvin cycle..."         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 9: Return to Backend                                         â”‚
â”‚  Service: local_ai_service                                          â”‚
â”‚                                                                     â”‚
â”‚  Response from brain service:                                       â”‚
â”‚    {                                                                â”‚
â”‚      "response": "Photosynthesis is the process...",               â”‚
â”‚      "model": "studymate"                                           â”‚
â”‚    }                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 10: Save Chat History (chat.py)                              â”‚
â”‚                                                                     â”‚
â”‚  Save to Supabase:                                                  â”‚
â”‚    {                                                                â”‚
â”‚      "course_id": "...",                                            â”‚
â”‚      "history": [                                                   â”‚
â”‚        {"role": "user", "content": "Explain photosynthesis"},      â”‚
â”‚        {"role": "model", "content": "Photosynthesis is..."}        â”‚
â”‚      ]                                                              â”‚
â”‚    }                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 11: Return to User                                           â”‚
â”‚                                                                     â”‚
â”‚  HTTP Response:                                                     â”‚
â”‚    {                                                                â”‚
â”‚      "response": "Photosynthesis is the process...",               â”‚
â”‚      "timestamp": "2024-12-15T10:30:00Z"                           â”‚
â”‚    }                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Different Flows Based on Intent

### Flow 1: Chitchat (e.g., "Hello!")

```
User: "Hello!"
  â†“
Router: {"intent": "chat", "needs_rag": false, "needs_history": false}
  â†“
Backend: Skip RAG search âœ“ (SAVES 200-300ms)
  â†“
Context: Minimal system prompt only
  [
    {"role": "system", "content": "You are StudyMate..."},
    {"role": "user", "content": "Hello!"}
  ]
  â†“
Core Model: "Hello! I'm StudyMate, your AI tutor..."
  â†“
User: Response in ~2.1s (30% faster!)
```

### Flow 2: Academic Query (e.g., "Explain photosynthesis")

```
User: "Explain photosynthesis"
  â†“
Router: {"intent": "academic", "needs_rag": true, "needs_history": false}
  â†“
Backend: Perform RAG search âœ“
  â†“
Context: Full system prompt + RAG materials
  [
    {"role": "system", "content": "You are StudyMate...\n[COURSE MATERIALS]\n..."},
    {"role": "user", "content": "Explain photosynthesis"}
  ]
  â†“
Core Model: "Based on your notes, photosynthesis is..."
  â†“
User: Response in ~2.8s (with full context)
```

### Flow 3: Follow-up (e.g., "Why did you say that?")

```
User: "Why did you say that?"
  â†“
Router: {"intent": "followup", "needs_rag": false, "needs_history": true}
  â†“
Backend: Skip RAG search âœ“, Load history âœ“
  â†“
Context: System prompt + previous conversation
  [
    {"role": "system", "content": "You are StudyMate..."},
    {"role": "user", "content": "What is gravity?"},
    {"role": "assistant", "content": "Gravity is a force..."},
    {"role": "user", "content": "Why did you say that?"}
  ]
  â†“
Core Model: "I mentioned that because in the previous question..."
  â†“
User: Response in ~2.3s (with history context)
```

### Flow 4: Safety Query (e.g., "How to hack a website")

```
User: "How to hack a website"
  â†“
Router: {"intent": "safety", "needs_rag": false, "needs_history": false}
  â†“
Backend: BLOCK IMMEDIATELY âœ“ (No AI call!)
  â†“
User: "I can't help with that request. I'm designed to assist with educational content only."
  â†“
Response in ~0.02s (instant blocking!)
```

---

## ğŸ“Š Key Differences from Old Architecture

### OLD Architecture (JSON Dump):

```python
# Backend always sends everything
training_json = {
    "instruction": "Hello!",
    "input": {
        "academic_info": {...},           # Always included
        "learning_preferences": {...},    # Always included
        "rag_chunks": [...],              # Always included (even if empty)
        "chat_history": [...]             # Always included (even if empty)
    }
}

# Brain service converts JSON to natural language
# Core model processes ~2000 tokens
# Response time: ~3.0s
```

### NEW Architecture (Adaptive ChatML):

```python
# Router decides what's needed
intent = {"intent": "chat", "needs_rag": false, "needs_history": false}

# Backend builds minimal context
messages = [
    {"role": "system", "content": "You are StudyMate..."},
    {"role": "user", "content": "Hello!"}
]

# Brain service uses ollama.chat() directly
# Core model processes ~200 tokens (90% less!)
# Response time: ~2.1s (30% faster!)
```

---

## ğŸ¯ Token Savings Breakdown

### Chitchat Query: "Hello!"

**Before**:
```
System prompt: 500 tokens
Academic info: 100 tokens
Preferences: 200 tokens
RAG chunks: 800 tokens (empty but formatted)
History: 400 tokens (empty but formatted)
User query: 10 tokens
TOTAL: ~2010 tokens
```

**After**:
```
System prompt: 150 tokens (minimal)
User query: 10 tokens
TOTAL: ~160 tokens (92% savings!)
```

### Academic Query: "Explain photosynthesis"

**Before**:
```
System prompt: 500 tokens
Academic info: 100 tokens
Preferences: 200 tokens
RAG chunks: 800 tokens
History: 400 tokens (empty but formatted)
User query: 20 tokens
TOTAL: ~2020 tokens
```

**After**:
```
System prompt: 200 tokens
Academic info: 50 tokens
Preferences: 150 tokens
RAG chunks: 800 tokens
User query: 20 tokens
TOTAL: ~1220 tokens (40% savings!)
```

---

## ğŸ”§ Code Flow Summary

### 1. Entry Point
```python
# python-backend/routers/chat.py
@router.post("/courses/{course_id}/chat")
async def save_chat_message(course_id, chat_request, user):
    # This is where everything starts
```

### 2. Classification
```python
# python-backend/services/intent_classifier.py
intent = await intent_classifier.classify(
    query=chat_request.message,
    subject=subject,
    grade=grade
)
# Returns: {"intent": "...", "needs_rag": bool, "needs_history": bool}
```

### 3. Conditional RAG
```python
# python-backend/routers/chat.py
if intent["needs_rag"]:
    search_results = await service_manager.processing_service.search_materials(...)
else:
    search_results = []  # Skip search!
```

### 4. Build Context
```python
# python-backend/services/context_service.py
messages = await context_service.build_adaptive_context(
    user_id=user.id,
    course_id=course_id,
    user_message=chat_request.message,
    intent=intent,
    search_results=search_results
)
# Returns: [{"role": "system", "content": "..."}, ...]
```

### 5. Generate Response
```python
# python-backend/services/local_ai_service.py
response_text = await local_ai_service.generate_chat_response(
    messages=messages,
    attachments=chat_request.attachments
)
# Sends to: http://localhost:8001/chat
```

### 6. Core Model
```python
# ai-brain/brain.py
@app.post("/chat")
async def chat_endpoint(request):
    response = await client.chat(
        model="studymate",
        messages=request["messages"]
    )
    return {"response": response['message']['content']}
```

---

## ğŸ¯ Summary

**The new backend flow**:
1. âœ… Classifies intent first (Gemma 3 270M)
2. âœ… Conditionally searches materials (only if needed)
3. âœ… Builds adaptive ChatML context (minimal tokens)
4. âœ… Sends to core model (ollama.chat API)
5. âœ… Returns response to user

**Key improvements**:
- ğŸš€ 60-90% token savings for simple queries
- âš¡ 30% faster responses for chitchat
- ğŸ›¡ï¸ Instant safety blocking
- ğŸ¯ Better accuracy (no irrelevant context)
- ğŸ”§ ChatML format (fixes hallucinations)

**The magic**: Router model decides what context to include, backend only fetches what's needed, core model gets clean, focused input!
